{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab-2: 모델 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 참값 데이타를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50248587  0.69897169  0.09331067  0.92824912  0.21490763  0.63365585\n",
      "  0.18222487  0.04554075  0.64247614  0.60887444  0.96813327  0.12638119\n",
      "  0.19702946  0.53860301  0.4195255   0.85900503  0.63436079  0.38915679\n",
      "  0.33004999  0.62783337  0.8381809   0.05473496  0.73950958  0.16498584\n",
      "  0.4788487   0.74077046  0.73386759  0.70165974  0.56896657  0.23074505\n",
      "  0.28082758  0.22752383  0.45054427  0.4036119   0.34776899  0.7780605\n",
      "  0.56144804  0.12812366  0.81973547  0.85203451  0.80357742  0.92493528\n",
      "  0.08116395  0.10966633  0.06412392  0.80074626  0.08598538  0.28902555\n",
      "  0.23946393  0.7459839   0.86061352  0.71083474  0.97787142  0.74870127\n",
      "  0.78042495  0.28677413  0.07878593  0.55979192  0.41589803  0.03423238\n",
      "  0.59088242  0.48733139  0.97915822  0.67063701  0.78859305  0.86891073\n",
      "  0.06033147  0.27852407  0.36681107  0.97425622  0.24822754  0.67957336\n",
      "  0.26463643  0.58711863  0.6340633   0.28685427  0.96239209  0.42957562\n",
      "  0.93870354  0.45335194  0.96876192  0.631666    0.49437821  0.95738167\n",
      "  0.4631114   0.74721014  0.82380146  0.85929286  0.24929871  0.24657759\n",
      "  0.68513083  0.69542581  0.97214073  0.26586717  0.50652111  0.77022076\n",
      "  0.1996998   0.58193743  0.60276431  0.73852581]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.float32(np.random.rand(100))  # 100개의 랜덤값을 만들기\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.00497174  2.3979435   1.18662131  2.85649824  1.42981529  2.26731157\n",
      "  1.36444974  1.0910815   2.28495216  2.21774888  2.93626642  1.25276232\n",
      "  1.39405894  2.07720613  1.83905101  2.71800995  2.26872158  1.77831364\n",
      "  1.66009998  2.25566673  2.6763618   1.10946989  2.47901917  1.32997167\n",
      "  1.95769739  2.48154092  2.46773529  2.40331936  2.13793325  1.46149015\n",
      "  1.56165516  1.45504761  1.90108848  1.8072238   1.69553804  2.55612087\n",
      "  2.12289619  1.25624728  2.63947105  2.70406914  2.60715485  2.84987068\n",
      "  1.16232789  1.2193327   1.12824786  2.6014924   1.17197073  1.57805109\n",
      "  1.47892785  2.49196768  2.72122717  2.42166948  2.95574284  2.49740267\n",
      "  2.56084991  1.57354832  1.15757191  2.11958385  1.83179605  1.06846476\n",
      "  2.18176484  1.97466278  2.95831633  2.34127402  2.57718611  2.73782158\n",
      "  1.12066293  1.55704808  1.73362207  2.94851255  1.49645507  2.3591466\n",
      "  1.52927279  2.17423725  2.26812649  1.57370853  2.92478418  1.85915124\n",
      "  2.87740707  1.90670395  2.93752384  2.26333189  1.98875642  2.91476345\n",
      "  1.9262228   2.49442029  2.64760303  2.71858573  1.49859738  1.49315524\n",
      "  2.37026167  2.3908515   2.94428158  1.53173435  2.01304221  2.54044151\n",
      "  1.39939964  2.16387486  2.20552874  2.47705173]\n"
     ]
    }
   ],
   "source": [
    "y_data = 2 * x_data + 1    # y = 2 * x + 1 의 모델에 의해 y값을 만들기\n",
    "                           # 나중에 찾고자 하는 파라미터는 2와 1이다. \n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b는 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W는 1x2 형태의 웨이트 변수 (균등 랜덤값으로 초기화)\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "\n",
    "# W를 x_data랑 곱하고  b를 더하기 \n",
    "y = W * x_data + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의 (define loss function)\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# 경사하강법으로 손실 함수를 최소화 (0.5는 학습 비율) \n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# loss를 최소화하는 W와 b를 찾는 학습 오퍼레이션을 정의\n",
    "# set the train operator which finds W and b which minimize loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 0.75731158] [ 2.31167841]\n",
      "20 [ 1.64430416] [ 1.19080019]\n",
      "40 [ 1.91629004] [ 1.04490328]\n",
      "60 [ 1.98029959] [ 1.01056755]\n",
      "80 [ 1.99536359] [ 1.00248706]\n",
      "100 [ 1.99890888] [ 1.00058532]\n",
      "120 [ 1.99974322] [ 1.00013781]\n",
      "140 [ 1.99993968] [ 1.00003231]\n",
      "160 [ 1.99998581] [ 1.00000763]\n",
      "180 [ 1.99999654] [ 1.00000179]\n"
     ]
    }
   ],
   "source": [
    "# 모든 변수를 초기화하는 오퍼레이션 정의 (operation which initializes all variables)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 세션 시작 (start session)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 200번 학습. 200번 train operation을 실행하기 (iterate 200 times the train operation)\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 복잡한 예제: \n",
    "https://gist.github.com/haje01/202ac276bace4b25dd3f 의 예제를 가지고 옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Numpy 랜덤으로 100개의 2-D 데이터 채우기. (float64 -> float32로 변환)\n",
    "x_data = np.float32(np.random.rand(2, 100))\n",
    "\n",
    "# 학습 레이블(목표값)의 참값을 (W_true = [0.1, 0.2], b_true = 0.3)으로 주고\n",
    "# 이 레이블을 사용하여 x_data에 대응되는 y_data를 생성함.\n",
    "#  W_true = [0.1, 0.2], b_true = 0.3는 우리가 찾고자 하는 파라미터임.\n",
    "\n",
    "y_data = np.dot([0.100, 0.200], x_data) + 0.300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b는 0\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# W는 1x2 형태의 웨이트 변수 (균등 랜덤값으로 초기화)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([1, 2], -1.0, 1.0))\n",
    "\n",
    "# W를 x_data랑 곱하고  b를 더하기 \n",
    "\n",
    "y = tf.matmul(W, x_data) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실함수 정의 및 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 손실 함수 정의 (define loss function)\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "\n",
    "# 경사하강법으로 손실 함수를 최소화 (0.5는 학습 비율) \n",
    "# Set the gradient descent optimizer with alpha = 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)\n",
    "\n",
    "# loss를 최소화하는 W와 b를 찾는 학습 오퍼레이션을 정의\n",
    "# set the train operator which finds W and b which minimize loss\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[ 0.10408878  0.60188019]] [ 0.1757575]\n",
      "20 [[ 0.15038893  0.30269998]] [ 0.21963277]\n",
      "40 [[ 0.13134578  0.2372088 ]] [ 0.26407373]\n",
      "60 [[ 0.11531273  0.21548128]] [ 0.28387114]\n",
      "80 [[ 0.10705741  0.20678824]] [ 0.29274935]\n",
      "100 [[ 0.10319819  0.20302892]] [ 0.29673919]\n",
      "120 [[ 0.10144191  0.20135903]] [ 0.29853329]\n",
      "140 [[ 0.10064906  0.20061083]] [ 0.29934028]\n",
      "160 [[ 0.100292    0.20027469]] [ 0.29970324]\n",
      "180 [[ 0.10013134  0.20012353]] [ 0.29986653]\n"
     ]
    }
   ],
   "source": [
    "# 모든 변수를 초기화하는 오퍼레이션 정의 (operation which initializes all variables)\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 세션 시작 (start session)\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 200번 학습. 200번 train operation을 실행하기 (iterate 200 times the train operation)\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:        \n",
    "        print (step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
